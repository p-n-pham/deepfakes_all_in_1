{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Utility functions\n",
    "\n",
    "def GetTime(video_seconds):\n",
    "\n",
    "    if (video_seconds < 0) :\n",
    "        return 00\n",
    "\n",
    "    else:\n",
    "        sec = timedelta(seconds=float(video_seconds))\n",
    "        d = datetime(1,1,1) + sec\n",
    "\n",
    "        instant = str(d.hour).zfill(2) + ':' + str(d.minute).zfill(2) + ':' + str(d.second).zfill(2) + str('.001')\n",
    "    \n",
    "        return instant\n",
    "\n",
    "def GetTotalTime(video_seconds):\n",
    "\n",
    "    sec = timedelta(seconds=float(video_seconds))\n",
    "    d = datetime(1,1,1) + sec\n",
    "    delta = str(d.hour) + ':' + str(d.minute) + \":\" + str(d.second)\n",
    "    \n",
    "    return delta\n",
    "\n",
    "def windows(signal, window_size, step_size):\n",
    "    if type(window_size) is not int:\n",
    "        raise AttributeError(\"Window size must be an integer.\")\n",
    "    if type(step_size) is not int:\n",
    "        raise AttributeError(\"Step size must be an integer.\")\n",
    "    for i_start in range(0, len(signal), step_size):\n",
    "        i_end = i_start + window_size\n",
    "        if i_end >= len(signal):\n",
    "            break\n",
    "        yield signal[i_start:i_end]\n",
    "\n",
    "def energy(samples):\n",
    "    return np.sum(np.power(samples, 2.)) / float(len(samples))\n",
    "\n",
    "def rising_edges(binary_signal):\n",
    "    previous_value = 0\n",
    "    index = 0\n",
    "    for x in binary_signal:\n",
    "        if x and not previous_value:\n",
    "            yield index\n",
    "        previous_value = x\n",
    "        index += 1\n",
    "\n",
    "def slicer(input_filename, output_dir, window_duration, silence_threshold, step_duration):\n",
    "    if step_duration is None:\n",
    "        step_duration = window_duration / 10.\n",
    "    else:\n",
    "        step_duration = step_duration\n",
    "\n",
    "    output_filename_prefix = os.path.splitext(os.path.basename(input_filename))[0]\n",
    "    dry_run = False\n",
    "\n",
    "    print(\"Splitting {} where energy is below {}% for longer than {}s.\".format(\n",
    "        input_filename,\n",
    "        silence_threshold * 100.,\n",
    "        window_duration\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Read and split the file\n",
    "\n",
    "    sample_rate, samples = input_data=wavfile.read(filename=input_filename, mmap=True)\n",
    "\n",
    "    max_amplitude = np.iinfo(samples.dtype).max\n",
    "    print('max_amplitude', max_amplitude)\n",
    "\n",
    "    max_energy = energy([max_amplitude])\n",
    "    print('max_energy', max_energy)\n",
    "\n",
    "    window_size = int(window_duration * sample_rate)\n",
    "    step_size = int(step_duration * sample_rate)\n",
    "\n",
    "    signal_windows = windows(\n",
    "        signal=samples,\n",
    "        window_size=window_size,\n",
    "        step_size=step_size\n",
    "    )\n",
    "\n",
    "    window_energy = (energy(w) / max_energy for w in tqdm(\n",
    "        signal_windows,\n",
    "        total=int(len(samples) / float(step_size))\n",
    "    ))\n",
    "\n",
    "    window_silence = (e > silence_threshold for e in window_energy)\n",
    "\n",
    "    cut_times = (r * step_duration for r in rising_edges(window_silence))\n",
    "    \n",
    "    # This is the step that takes long, since we force the generators to run.\n",
    "    print(\"Finding silences...\")\n",
    "    cut_samples = [int(t * sample_rate) for t in cut_times]\n",
    "    \n",
    "    cut_samples.append(-1)\n",
    "    cut_ranges = [(i, cut_samples[i], cut_samples[i+1]) for i in range(len(cut_samples) - 1)]\n",
    "\n",
    "    video_sub = {str(i) : [str(GetTime(((cut_samples[i])/sample_rate))), \n",
    "                        str(GetTime(((cut_samples[i+1])/sample_rate)))] \n",
    "                for i in range(len(cut_samples) - 1)}\n",
    "\n",
    "    for i, start, stop in tqdm(cut_ranges):\n",
    "        output_file_path = \"{}_{:03d}.wav\".format(\n",
    "            os.path.join(output_dir, output_filename_prefix),\n",
    "            i\n",
    "        )\n",
    "        if not dry_run:\n",
    "            wavfile.write(\n",
    "                filename=output_file_path,\n",
    "                rate=sample_rate,\n",
    "                data=samples[start:stop]\n",
    "            )\n",
    "        else:\n",
    "            print(\"Not writing file {}\".format(output_file_path))\n",
    "            \n",
    "    with open(os.path.join(output_dir, output_filename_prefix+'.json'), 'w') as output:\n",
    "        json.dump(video_sub, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting /home/k54728/working/deepfakes/data/5_voice_cloning_train/1_input_audio/Part_3_raw.wav where energy is below 0.01% for longer than 0.6s.\n",
      "max_amplitude 32767\n",
      "max_energy 1073676289.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 15/180141 [00:00<21:14, 141.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding silences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 179942/180141 [22:01<00:01, 136.14it/s]\n",
      "  0%|          | 0/138 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/k54728/working/deepfakes/data/5_voice_cloning_train/sliced_audio/Part_3_raw_000.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(input_dir):\n\u001b[1;32m     17\u001b[0m     input_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_dir, filename)\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mslicer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_duration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_silence_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilence_threshold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msilence_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_duration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_duration\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 117\u001b[0m, in \u001b[0;36mslicer\u001b[0;34m(input_filename, output_dir, window_duration, silence_threshold, step_duration)\u001b[0m\n\u001b[1;32m    112\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{:03d}\u001b[39;00m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    113\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, output_filename_prefix),\n\u001b[1;32m    114\u001b[0m     i\n\u001b[1;32m    115\u001b[0m )\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dry_run:\n\u001b[0;32m--> 117\u001b[0m     \u001b[43mwavfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m:\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot writing file \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(output_file_path))\n",
      "File \u001b[0;32m~/miniconda3/envs/deepfake-env/lib/python3.11/site-packages/scipy/io/wavfile.py:767\u001b[0m, in \u001b[0;36mwrite\u001b[0;34m(filename, rate, data)\u001b[0m\n\u001b[1;32m    765\u001b[0m     fid \u001b[38;5;241m=\u001b[39m filename\n\u001b[1;32m    766\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 767\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m fs \u001b[38;5;241m=\u001b[39m rate\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/k54728/working/deepfakes/data/5_voice_cloning_train/sliced_audio/Part_3_raw_000.wav'"
     ]
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Last Acceptable Values\n",
    "\n",
    "min_silence_length = 0.3\n",
    "silence_threshold = 1e-3\n",
    "step_duration = 0.03/10\n",
    "\n",
    "'''\n",
    "# Change the arguments and the input file here\n",
    "input_dir = '/home/k54728/working/deepfakes/data/5_voice_cloning_train/1_input_audio'\n",
    "output_dir = '/home/k54728/working/deepfakes/data/5_voice_cloning_train/dataset_raw/sliced_audio'\n",
    "\n",
    "# Remove old sliced files\n",
    "if os.path.isdir(output_dir): \n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "# Create directory if not exist\n",
    "if not os.path.exists(output_dir):\n",
    "   os.makedirs(output_dir)\n",
    "\n",
    "min_silence_length = 0.6  # The minimum length of silence at which a split may occur [seconds]. Defaults to 3 seconds.\n",
    "silence_threshold = 1e-4  # The energy level (between 0.0 and 1.0) below which the signal is regarded as silent.\n",
    "step_duration = 0.03/10   # The amount of time to step forward in the input file after calculating energy. Smaller value = slower, but more accurate silence detection. Larger value = faster, but might miss some split opportunities. Defaults to (min-silence-length / 10.).\n",
    "\n",
    "for filename in os.listdir(input_dir):\n",
    "    input_filename = os.path.join(input_dir, filename)\n",
    "    slicer(input_filename, output_dir, window_duration=min_silence_length, silence_threshold = silence_threshold, step_duration=step_duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "svc-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
